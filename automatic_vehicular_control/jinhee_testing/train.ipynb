{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory for single ring experiments and the number of training runs\n",
    "single_folder = '../pareto/single_ring'\n",
    "single_num_runs = 3  # Number of training runs for each experiment\n",
    "\n",
    "def single_ring_train_script_text(\n",
    "        output_log='marcus_output-%j.log',\n",
    "        run_dir='.', \n",
    "        worker_kwargs=[{'circumference': 1000}], \n",
    "        n_workers=45,\n",
    "        n_rollouts_per_step=45,\n",
    "        warmup_steps=2000,\n",
    "        skip_stat_steps=5000,\n",
    "        horizon=5000,\n",
    "        global_reward=True,\n",
    "        n_steps=50,\n",
    "        alg='TRPO',\n",
    "        use_critic=False,\n",
    "        gamma=0.9995,\n",
    "        beta=0,\n",
    "        scale_ttc=1,\n",
    "        scale_drac=1,\n",
    "        seed_np=False,\n",
    "        seed_torch=False,\n",
    "        residual_transfer=False,\n",
    "        mrtl=False,\n",
    "        handcraft=False,\n",
    "        step_save=False,\n",
    "        lr=1e-4,\n",
    "        wb=False,\n",
    "        tb=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Generate a script text for training on a single ring road environment.\n",
    "    The script is formatted to be runnable on the supercloud.\n",
    "\n",
    "    Args:\n",
    "        output_log (str): Output log filename pattern.\n",
    "        run_dir (str): The directory where the script will be executed.\n",
    "        worker_kwargs (list): List of dictionaries containing worker-specific parameters.\n",
    "        n_workers (int): Number of worker processes.\n",
    "        n_rollouts_per_step (int): Number of rollouts per training step.\n",
    "        warmup_steps (int): Number of warmup steps before training.\n",
    "        skip_stat_steps (int): Number of steps to skip when collecting statistics.\n",
    "        horizon (int): Length of each rollout.\n",
    "        global_reward (bool): Whether to use global reward in training.\n",
    "        n_steps (int): Total number of training steps.\n",
    "        alg (str): The reinforcement learning algorithm to use.\n",
    "        use_critic (bool): Whether to use a critic in the algorithm.\n",
    "        gamma (float): Discount factor for future rewards.\n",
    "        beta (float): Coefficient for regularization terms.\n",
    "        scale_ttc (float): Scaling factor for Time-To-Collision.\n",
    "        scale_drac (float): Scaling factor for deceleration rate.\n",
    "        seed_np (bool): Whether to seed NumPy random number generator.\n",
    "        seed_torch (bool): Whether to seed PyTorch random number generator.\n",
    "        residual_transfer (bool): Whether to use residual transfer learning.\n",
    "        mrtl (bool): Whether to use multi-round transfer learning.\n",
    "        handcraft (bool): Whether to use handcrafted features.\n",
    "        step_save (bool): Whether to save the model at each step.\n",
    "        lr (float): Learning rate for the optimizer.\n",
    "        wb (bool): Whether to use Weights & Biases for logging.\n",
    "        tb (bool): Whether to use TensorBoard for logging.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted script text ready to be submitted to the supercloud.\n",
    "    \"\"\"\n",
    "    # Format the script text with the provided arguments\n",
    "    script_text = (f'''#!/bin/sh\n",
    "\n",
    "#SBATCH -o {output_log}\n",
    "#SBATCH --time=72:00:00          # Total run time limit (HH:MM:SS)\n",
    "#SBATCH -c {n_workers}\n",
    "\n",
    "'''\n",
    "    f'''python $F/ring.py {run_dir} \"worker_kwargs={worker_kwargs}\" \"n_workers={n_workers}\" \"n_rollouts_per_step={n_rollouts_per_step}\" \"warmup_steps={warmup_steps}\"'''\n",
    "    f''' \"skip_stat_steps={skip_stat_steps}\" \"horizon={horizon}\" \"global_reward={global_reward}\" \"n_steps={n_steps}\" \"alg='{alg}'\" \"use_critic={use_critic}\" \"gamma={gamma}\" \"beta={beta}\"'''\n",
    "    f''' \"scale_ttc={scale_ttc}\" \"scale_drac={scale_drac}\" \"seed_np={seed_np}\" \"seed_torch={seed_torch}\" \"residual_transfer={residual_transfer}\" \"mrtl={mrtl}\" \"handcraft={handcraft}\" \"step_save={step_save}\" \"lr={lr}\" \"wb={wb}\" \"tb={tb}\" '''\n",
    "                      )\n",
    "    \n",
    "    return script_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_with_contents(file_path, contents):\n",
    "    \"\"\"\n",
    "    Create a file at the specified path and write the provided contents to it.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file to be created.\n",
    "        contents (str): The content to write into the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(file_path)\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(contents)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def submit_job(script_path):\n",
    "    \"\"\"\n",
    "    Submit a job to the job scheduler using the LLsub command.\n",
    "\n",
    "    Args:\n",
    "        script_path (str): The path to the script to be submitted.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The standard output and standard error from the submission command.\n",
    "    \"\"\"\n",
    "    output = subprocess.run(f'LLsub {script_path}', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    print(output)\n",
    "    return output.stdout, output.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pareto/single_ring/seeding2/train1.sh\n"
     ]
    }
   ],
   "source": [
    "random_seed = 5\n",
    "\n",
    "# Define the directory for storing results from seeded single ring experiments\n",
    "single_ring_seed_dir = f'{single_folder}/seeding2'\n",
    "cur_dir = single_ring_seed_dir\n",
    "\n",
    "output_logs = []\n",
    "output_log_name = f'{single_folder}/train1/train.log'\n",
    "beta = 0.0 #optimize performance\n",
    "\n",
    "train_script_text = single_ring_train_script_text(output_log=output_log_name, run_dir=cur_dir, beta=0.0, n_steps=400, seed_torch=random_seed, seed_np=random_seed)\n",
    "train_script_path = f'{cur_dir}/train1.sh'\n",
    "create_file_with_contents(train_script_path, train_script_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletedProcess(args='LLsub ../pareto/single_ring/seeding2/train1.sh', returncode=127, stdout='', stderr='/bin/sh: LLsub: command not found\\n')\n"
     ]
    }
   ],
   "source": [
    "out, err = submit_job(train_script_path)\n",
    "output_logs.append(output_log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../pareto/single_ring/train1/train.log']\n"
     ]
    }
   ],
   "source": [
    "print(output_logs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
